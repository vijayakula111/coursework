{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking for an edge in winning Jeopardy show\n",
    "------------\n",
    "Jeopardy is a popular TV show in the US where participants answer questions to win money. It's been running for a few decades, and is a major force in popular culture.\n",
    "\n",
    "Let's say you want to compete on Jeopardy, and you're looking for any edge you can get to win. In this project, we'll work with a dataset of Jeopardy questions to figure out some patterns in the questions that could help you win.\n",
    "\n",
    "The dataset is named `JEOPARDY_CSV.csv`, and contains over `200000 rows` from the beginning of a full dataset of Jeopardy questions, which you can download [here](https://www.reddit.com/r/datasets/comments/1uyd0t/200000_jeopardy_questions_in_a_json_file)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import re\n",
    "from scipy.stats import chisquare\n",
    "import numpy as np\n",
    "\n",
    "# Settings\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(216930, 7)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Show Number</th>\n",
       "      <th>Air Date</th>\n",
       "      <th>Round</th>\n",
       "      <th>Category</th>\n",
       "      <th>Value</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>HISTORY</td>\n",
       "      <td>$200</td>\n",
       "      <td>For the last 8 years of his life, Galileo was ...</td>\n",
       "      <td>Copernicus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>ESPN's TOP 10 ALL-TIME ATHLETES</td>\n",
       "      <td>$200</td>\n",
       "      <td>No. 2: 1912 Olympian; football star at Carlisl...</td>\n",
       "      <td>Jim Thorpe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Show Number    Air Date      Round                         Category  Value  \\\n",
       "0         4680  2004-12-31  Jeopardy!                          HISTORY   $200   \n",
       "1         4680  2004-12-31  Jeopardy!  ESPN's TOP 10 ALL-TIME ATHLETES   $200   \n",
       "\n",
       "                                            Question      Answer  \n",
       "0  For the last 8 years of his life, Galileo was ...  Copernicus  \n",
       "1  No. 2: 1912 Olympian; football star at Carlisl...  Jim Thorpe  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Show Number</th>\n",
       "      <th>Air Date</th>\n",
       "      <th>Round</th>\n",
       "      <th>Category</th>\n",
       "      <th>Value</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>216928</th>\n",
       "      <td>4999</td>\n",
       "      <td>2006-05-11</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>QUOTATIONS</td>\n",
       "      <td>$2000</td>\n",
       "      <td>From Ft. Sill, Okla. he made the plea, Arizona...</td>\n",
       "      <td>Geronimo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216929</th>\n",
       "      <td>4999</td>\n",
       "      <td>2006-05-11</td>\n",
       "      <td>Final Jeopardy!</td>\n",
       "      <td>HISTORIC NAMES</td>\n",
       "      <td>None</td>\n",
       "      <td>A silent movie title includes the last name of...</td>\n",
       "      <td>Grigori Alexandrovich Potemkin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Show Number    Air Date             Round        Category  Value  \\\n",
       "216928         4999  2006-05-11  Double Jeopardy!      QUOTATIONS  $2000   \n",
       "216929         4999  2006-05-11   Final Jeopardy!  HISTORIC NAMES   None   \n",
       "\n",
       "                                                 Question  \\\n",
       "216928  From Ft. Sill, Okla. he made the plea, Arizona...   \n",
       "216929  A silent movie title includes the last name of...   \n",
       "\n",
       "                                Answer  \n",
       "216928                        Geronimo  \n",
       "216929  Grigori Alexandrovich Potemkin  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Index(['Show Number', ' Air Date', ' Round', ' Category', ' Value',\n",
       "       ' Question', ' Answer'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading dataset\n",
    "\n",
    "jeopardy = pd.read_csv(\"JEOPARDY_CSV.csv\")\n",
    "jeopardy.shape\n",
    "jeopardy.head(2)\n",
    "jeopardy.tail(2)\n",
    "jeopardy.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Show Number', 'Air Date', 'Round', 'Category', 'Value', 'Question',\n",
       "       'Answer'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trimming spaces in column names\n",
    "\n",
    "jeopardy.columns = [col.strip() for col in jeopardy.columns]\n",
    "jeopardy.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------\n",
    "Lets normalize the text columns `Question` and `Answer`. The idea is to lowercase all words and remove punctuations. This will avoid different result for the same words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imported re module\n",
    "\n",
    "def norm_text(input_string):\n",
    "    input_string = str(input_string)\n",
    "    return re.sub(\"[^A-Za-z0-9\\s]\", \"\", input_string).lower()\n",
    "    \n",
    "jeopardy[\"clean_question\"] = jeopardy['Question'].apply(norm_text)\n",
    "jeopardy[\"clean_answer\"] = jeopardy['Answer'].apply(norm_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also clean `Value` and `Air Date` columns.\n",
    "- Removing '$' and ',' from **Value** column and coverting it to int\n",
    "- Coverting **Air Date** to datetime format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_value(input_string):\n",
    "    input_string = re.sub(\"[^A-Za-z0-9\\s]\", \"\", input_string)\n",
    "    try:\n",
    "        input_string = int(input_string)\n",
    "    except Exception:\n",
    "        input_string = 0\n",
    "    return input_string    \n",
    "\n",
    "jeopardy[\"clean_value\"] = jeopardy['Value'].apply(norm_value)\n",
    "jeopardy[\"Air Date\"] = pd.to_datetime(jeopardy['Air Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "In order to figure out whether to study past questions, study general knowledge, or not study it all, it would be helpful to figure out two things:\n",
    "\n",
    "- How often the answer is deducible from the question.\n",
    "- How often new questions are repeats of older questions.\n",
    "\n",
    "We can answer the first question by seeing how many times words in the answer also occur in the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deducible(row):\n",
    "    split_answer = row[\"clean_answer\"].split(' ')\n",
    "    split_question = row[\"clean_question\"].split(' ')\n",
    "    \n",
    "    # removing 'the' word if exists from split_answer as it is quite common\n",
    "    if \"the\" in split_answer:\n",
    "        split_answer = [i for i in split_answer if i != 'the']\n",
    "    if len(split_answer) == 0:\n",
    "        return 0\n",
    "    # check for a match word in question\n",
    "    match_count = 0\n",
    "    for ans in split_answer:\n",
    "        if ans in split_question:\n",
    "            match_count += 1\n",
    "    \n",
    "    return match_count/len(split_answer)\n",
    "\n",
    "jeopardy['answer_in_question'] = jeopardy.apply(deducible, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of times one or more words from answer present in question: 27473\n",
      "mean of 'answer_in_question' column: 0.05879718229728192\n"
     ]
    }
   ],
   "source": [
    "print(\"number of times one or more words from answer present in question:\", jeopardy[jeopardy['answer_in_question'] != 0].shape[0])\n",
    "print(\"mean of 'answer_in_question' column:\", jeopardy['answer_in_question'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer terms in the question\n",
    "The answer only appears in the question about 6% of the time. This isn't a huge number, and means that we probably can't just hope that hearing a question will enable us to figure out the answer. We'll probably have to study."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------\n",
    "Now let's investigate how often new questions are repeats of older ones.\n",
    "- we shall look at words that are atleast 6 characters, which enables us to filter out words like **the** and **than**, which are commonly used, but don't tell you a lot about a question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort df by date\n",
    "jeopardy = jeopardy.sort_values(\"Air Date\")\n",
    "\n",
    "question_overlap = []\n",
    "terms_used = set()\n",
    "for i,row in jeopardy.iterrows():\n",
    "    split_question = row['clean_question'].split(' ')\n",
    "    split_question = [q for q in split_question if len(q) >= 6]\n",
    "    \n",
    "    match_count = 0\n",
    "    for each in split_question:\n",
    "        if each in terms_used:\n",
    "            match_count += 1\n",
    "        terms_used.add(each)\n",
    "    if len(split_question) > 0:\n",
    "        match_count = match_count/len(split_question)\n",
    "    question_overlap.append(match_count)\n",
    "    \n",
    "jeopardy['question_overlap'] = question_overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean of 'question_overlap' column: 0.8727083792207625\n"
     ]
    }
   ],
   "source": [
    "print(\"mean of 'question_overlap' column:\", jeopardy['question_overlap'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question overlap\n",
    "There is about 87% overlap between terms in new questions and terms in old questions. This makes it relatively significant, that it's worth looking more into the recycling of questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------\n",
    "Let's say we only want to study questions that pertain to high value questions instead of low value questions. This will help us earn more money when we're on Jeopardy.\n",
    "\n",
    "Doing this for all of the words would take a very long time, so we'll just do it for a small sample now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def high_value(value):\n",
    "    if value > 800:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "jeopardy['high_value'] = jeopardy['clean_value'].apply(high_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pistons',\n",
       " 'hrefhttpwwwjarchivecommedia20040714j18jpg',\n",
       " 'biochemistry',\n",
       " 'neoconservatives',\n",
       " 'fuller']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[(2, 7), (0, 1), (0, 2), (1, 1), (5, 13)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compare_word(word):\n",
    "    low_count = 0\n",
    "    high_count = 0\n",
    "    for idx, row in jeopardy.iterrows():\n",
    "        split_question = row['clean_question'].split(' ')\n",
    "        if word in split_question:\n",
    "            if row['high_value'] == 1:\n",
    "                high_count += 1\n",
    "            low_count += 1\n",
    "    return high_count, low_count\n",
    "\n",
    "observed_expected = []\n",
    "comparison_terms = list(terms_used)[0:5]\n",
    "\n",
    "for term in comparison_terms:\n",
    "    observed_expected.append(compare_word(term))\n",
    "\n",
    "comparison_terms    \n",
    "observed_expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Power_divergenceResult(statistic=0.16455916070771673, pvalue=0.6849932289997671),\n",
       " Power_divergenceResult(statistic=0.3949764642333513, pvalue=0.5296950912486695),\n",
       " Power_divergenceResult(statistic=0.7899529284667026, pvalue=0.3741143592744989),\n",
       " Power_divergenceResult(statistic=0.46338644448358013, pvalue=0.49604555208958945),\n",
       " Power_divergenceResult(statistic=0.002551837432310809, pvalue=0.9597114268675199)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high_value_count = jeopardy[jeopardy[\"high_value\"] == 1].shape[0]\n",
    "low_value_count = jeopardy[jeopardy[\"high_value\"] == 0].shape[0]\n",
    "\n",
    "chi_squared = []\n",
    "for obs in observed_expected:\n",
    "    total = sum(obs)\n",
    "    total_prop = total / jeopardy.shape[0]\n",
    "    high_value_exp = total_prop * high_value_count\n",
    "    low_value_exp = total_prop * low_value_count\n",
    "    \n",
    "    observed = np.array([obs[0], obs[1]])\n",
    "    expected = np.array([high_value_exp, low_value_exp])\n",
    "    chi_squared.append(chisquare(observed, expected))\n",
    "\n",
    "chi_squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chi-squared results\n",
    "None of the terms had a significant difference in usage between high value and low value rows. Additionally, the frequencies were all lower than 5, so the chi-squared test isn't as valid. It would be better to run this test with only terms that have higher frequencies."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
